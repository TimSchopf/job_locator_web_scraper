{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used websites:\n",
    "\n",
    "https://codelike.pro/create-a-crawler-with-rotating-ip-proxy-in-python/  \n",
    "http://jonathansoma.com/lede/foundations-2017/classes/adv-scraping/advanced-scraping-form-submission/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a request object from given url with random user agent and random proxy\n",
    "def request(url:str,request_type='get',post_params={}) -> requests.models.Response:\n",
    "    \n",
    "    # check parameter requirements\n",
    "    if request_type != 'get' and request_type != 'post':\n",
    "        raise ValueError(\"request_type must be 'get' or 'post' of type str\")\n",
    "        \n",
    "    if type(post_params) is not dict:\n",
    "        raise ValueError(\"post_params must be of type dict()\")\n",
    "        \n",
    "    if len(post_params) > 0:\n",
    "        if request_type != 'post':\n",
    "            raise ValueError(\"post_params can only be passed if request_type is set to 'post'\")\n",
    "    \n",
    "    #  disable ANY annoying exception with a fallback to default user agent if anything goes wrong\n",
    "    ua = UserAgent(fallback = 'Mozilla/5.0 (Windows; U; Windows NT 6.1; zh-HK) AppleWebKit/533.18.1 (KHTML, like Gecko) Version/5.0.2 Safari/533.18.5')\n",
    "\n",
    "    # update saved database of user agents\n",
    "    # fake_useragent stores collected data at os temp dir\n",
    "    print('update user agent database')\n",
    "    ua.update()\n",
    "    \n",
    "    print('get proxy list')\n",
    "    # will contain proxies [ip, port]\n",
    "    proxies = []\n",
    "\n",
    "    # retrieve latest proxies from website\n",
    "    proxies_req = requests.get(url='https://www.sslproxies.org/', headers={'user-agent': ua.random})\n",
    "    proxies_req.encoding = 'utf-8'\n",
    "\n",
    "    # create beatifulsoup instance, parse html and get section with proxy list of website\n",
    "    parsed_html = BeautifulSoup(proxies_req.text, 'html.parser')\n",
    "    proxies_table = parsed_html.find(id='proxylisttable')\n",
    "\n",
    "    # save proxies from proxy list of website in the array\n",
    "    for row in proxies_table.tbody.find_all('tr'):\n",
    "        proxies.append({\n",
    "        'ip':   row.find_all('td')[0].string,\n",
    "        'port': row.find_all('td')[1].string\n",
    "      })\n",
    "        \n",
    "    # retrieve a random index proxy\n",
    "    def random_proxy_idx():\n",
    "        return random.randint(0, len(proxies) - 1)\n",
    "    \n",
    "    print('try proxies')\n",
    "    # try if proxy server is running, if not try other random proxy and user agent, try maximum x times then exit loop\n",
    "    proxy_is_good = False\n",
    "    i = 0\n",
    "    x = 10\n",
    "    while not proxy_is_good:\n",
    "    \n",
    "        # get dict for random proxy \n",
    "        random_proxy = proxies[random_proxy_idx()]\n",
    "        random_proxy_dict = {'http': 'http://' + random_proxy['ip'] + ':' + random_proxy['port'],\n",
    "                        'https': 'https://' + random_proxy['ip'] + ':' + random_proxy['port']}\n",
    "    \n",
    "        # try to get request object from url with random user agent and random proxy\n",
    "        try:\n",
    "            if request_type == 'get':\n",
    "                req = requests.get(url=url, headers={'user-agent': ua.random},proxies=random_proxy_dict)\n",
    "            elif request_type == 'post':\n",
    "                req = requests.get(url=url, headers={'user-agent': ua.random},proxies=random_proxy_dict)\n",
    "            else:\n",
    "                raise ValueError(\"request_type must be 'get' or 'post' of type str\")\n",
    "                \n",
    "        # if anything goes wrong try again with differnt user agent and proxy\n",
    "        except:\n",
    "            print('Error',random_proxy)\n",
    "            if i == x:\n",
    "                print('All',i,'proxies are not reachable')\n",
    "                break\n",
    "            i += 1\n",
    "        # if everything goes right, end loop and return request object\n",
    "        else:\n",
    "            proxy_is_good = True\n",
    "            print('Success',random_proxy)\n",
    "    return req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update user agent database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error occurred during loading data. Trying to use cache server https://fake-useragent.herokuapp.com/browsers/0.1.11\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\fake_useragent\\utils.py\", line 67, in get\n",
      "    context=context,\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\urllib\\request.py\", line 223, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\urllib\\request.py\", line 526, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\urllib\\request.py\", line 544, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\urllib\\request.py\", line 504, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\urllib\\request.py\", line 1346, in http_open\n",
      "    return self.do_open(http.client.HTTPConnection, req)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\urllib\\request.py\", line 1321, in do_open\n",
      "    r = h.getresponse()\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\http\\client.py\", line 1331, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\http\\client.py\", line 297, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\http\\client.py\", line 258, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\socket.py\", line 586, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\fake_useragent\\utils.py\", line 166, in load\n",
      "    verify_ssl=verify_ssl,\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\fake_useragent\\utils.py\", line 122, in get_browser_versions\n",
      "    verify_ssl=verify_ssl,\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\fake_useragent\\utils.py\", line 84, in get\n",
      "    raise FakeUserAgentError('Maximum amount of retries reached')\n",
      "fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get proxy list\n",
      "try proxies\n",
      "Success {'ip': '193.238.98.206', 'port': '57437'}\n"
     ]
    }
   ],
   "source": [
    "req = request('https://www.daimler.com/karriere/jobsuche/', request_type='post', post_params={'j':2})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
